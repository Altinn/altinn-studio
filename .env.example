# Environment Configuration Example
#
# For local development:
#   Copy this file to .env and use the local configuration values below
#
# For Docker deployment:
#   Copy this file to .env.docker and use the Docker configuration values below

# Azure OpenAI Configuration (Preferred)
AZURE_API_KEY=your_azure_api_key_here
AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2024-12-01-preview
AZURE_DEPLOYMENT_NAME=gpt-4o-mini-2M-tps

# Multi-Model Configuration for Different Agent Roles
# Planner: Complex reasoning, multi-step planning (use powerful model)
LLM_MODEL_PLANNER=gpt-4o-2M-tps  # or gpt-4-turbo for best results
LLM_VERSION_PLANNER=2024-11-20
LLM_TEMPERATURE_PLANNER=0.3

# Actor: Precise code generation and patch creation
LLM_MODEL_ACTOR=gpt-4.1  # Fast and accurate (better than gpt-5 for code generation)
LLM_VERSION_ACTOR=2025-04-14
LLM_TEMPERATURE_ACTOR=0.1  # Precise generation

# Reviewer: Code review and validation
LLM_MODEL_REVIEWER=gpt-4o-2M-tps
LLM_VERSION_REVIEWER=2024-11-20
LLM_TEMPERATURE_REVIEWER=0.2

# Verifier: Deterministic checks
LLM_MODEL_VERIFIER=gpt-4o-mini-2M-tps
LLM_VERSION_VERIFIER=2024-07-18
LLM_TEMPERATURE_VERIFIER=0.0

# Assistant: Q&A and read-only assistance
LLM_MODEL_ASSISTANT=gpt-4o-mini-2M-tps  # Fast responses for chat
LLM_VERSION_ASSISTANT=2024-07-18
# LLM_TEMPERATURE_ASSISTANT=0.1  # Optional - some models don't support custom temperature, leave unset to use model default

# Fallback OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1

# Altinn Studio Integration
ALTINN_STUDIO_APPS_PATH=/Users/yourname/Apps

# Gitea Configuration
GITEA_URL=http://studio.localhost:3000/api/v1 # or http://host.docker.internal:3000/api/v1
GITEA_BASE_URL=http://studio.localhost:3000 # or http://host.docker.internal:3000
GITEA_API_TOKEN=your_gitea_token_here
GITEA_LOCAL_TOKEN=your_gitea_token_here

# MCP Server Configuration
MCP_SERVER_URL=http://localhost:8069/sse # or http://host.docker.internal:8069/sse
MCP_SERVER_EXPECTED_VERSION=1.0.0

# Frontend API
FRONTEND_API_HOST=0.0.0.0
FRONTEND_API_PORT=8071

# Logging
LOG_LEVEL=INFO
DEBUG=false
ENVIRONMENT=development

# Langfuse Configuration

# For Langfuse Cloud (https://cloud.langfuse.com)
LANGFUSE_SECRET_KEY=sk-lf-...  # Get from Langfuse project settings
LANGFUSE_PUBLIC_KEY=pk-lf-...  # Get from Langfuse project settings
LANGFUSE_HOST=https://cloud.langfuse.com

# For Self-Hosted Langfuse
# LANGFUSE_SECRET_KEY=your-secret-key
# LANGFUSE_PUBLIC_KEY=your-public-key
# LANGFUSE_HOST=http://localhost:3000

# Optional Configuration
LANGFUSE_ENABLED=true  # Set to 'false' to disable tracing
LANGFUSE_RELEASE=altinity-agents-v1  # Version/release tag for traces
LANGFUSE_ENVIRONMENT=development  # Environment tag (development, staging, production)
