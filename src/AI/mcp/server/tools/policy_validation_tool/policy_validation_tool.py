import os
import json
import xml.etree.ElementTree as ET
from typing import Dict, Any, List, Optional
from mcp.types import ToolAnnotations


# Third-party imports
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser

from server.tools import register_tool
from server.tools.policy_tool.static import all_roles
from server.config import LLM_PROMPTS
from server.config import (
    AZURE_ENDPOINT,
    API_KEY,
    DEPLOYMENT_NAME,
    LLM_CONFIG
)


@register_tool(
    name="policy_validation_tool",
    description="""
Validates authorization rules against user requirements using LLM analysis.

## Purpose
Check if policy.xml rules match the desired access control requirements.

## ⚠️ PREREQUISITE - MANDATORY
You MUST call `policy_summarization_tool` FIRST to get the `policy_rules` parameter.
This tool CANNOT work without the output from policy_summarization_tool.

## Required Parameters
- `query`: Description of desired access control (e.g., "Only accountants should access financial data")
- `policy_rules`: Output from `policy_summarization_tool` - the summarized rules dict/list

## Correct Usage Flow
```
1. policy_summarization_tool(xml_content="<Policy>...</Policy>")
   → Returns: {"rules": [...]}
2. policy_validation_tool(query="...", policy_rules=<output from step 1>)
```

## Returns
- `status`: "success" | "warning" | "error"
- `llm_analysis`: Analysis showing which rules match/deviate from requirements

## When to Use
✅ After `policy_summarization_tool` to validate rules against requirements
✅ After modifying policy.xml to verify changes meet requirements
✅ To audit existing policies against business requirements

## When NOT to Use
❌ WITHOUT first calling `policy_summarization_tool` - will fail
❌ To understand policy.xml format (use `policy_tool` instead)
❌ To get a readable summary (use `policy_summarization_tool` instead)

## Common Errors
- "No policy rules provided" → You forgot to call policy_summarization_tool first
- Empty results → The policy_rules parameter is malformed
""",
    title="Policy Validation Tool",
    annotations=ToolAnnotations(
        title="Policy Validation Tool",
        readOnlyHint=True
    )
)
def policy_validation_tool(user_goal: str, query: str, policy_rules: dict | list) -> dict:
    """
    Validates a policy file based on match with the user query.
    A server-side LLM is used to analyze the rules in the policy file and compare all authorization rules with the user query.
    
    Args:
        user_goal: The EXACT, VERBATIM user prompt or request - do not summarize or paraphrase (mandatory for tracing)
        query: The user query for policy validation
        policy_rules: Summarization of rules in policy, generated by policy_summarization_tool.
                     Can be either a dictionary with a 'rules' key or a direct list of rules.
    
    Returns:
        A dictionary containing the LLM analysis.
        The analaysis contains the user query, the rules that matches the query, and the rules that does not match the query.
    """
    
    #Check if policy rules is provided
    if not policy_rules:
        return {
            "status": "error",
            "error_code": "MISSING_PREREQUISITE",
            "message": "PREREQUISITE_ERROR: No policy_rules provided. You MUST call policy_summarization_tool FIRST "
                       "to generate the policy_rules parameter. This tool cannot work without it.",
            "hint": "Call policy_summarization_tool(xml_content='<your policy XML>') first, then pass its output as policy_rules.",
            "required_flow": "1. policy_summarization_tool(xml_content) → 2. policy_validation_tool(query, policy_rules)",
            "retry_allowed": False
        }

    try:
        #Converts policy rules to string
        policy_rules_string = convert_policy_rules_to_string(policy_rules)
        
        # Get LLM analysis of validation results based on user query
        llm_analysis = validate_policy_with_llm(query, policy_rules_string)
        
        # Return both validation results and LLM analysis
        return {
            #"validation_results": validation_results,
            "llm_analysis": llm_analysis
        }
    except Exception as e:
        return {"status": "error", "message": f"Error validating policy file: {str(e)}"}

# Initialize Azure OpenAI LLM for policy validation
policy_validation_llm = AzureChatOpenAI(
    azure_endpoint=AZURE_ENDPOINT,
    api_key=API_KEY,
    api_version=LLM_CONFIG["API_VERSION"],
    deployment_name=DEPLOYMENT_NAME,
    temperature=0.1,  # Low temperature for consistent analysis
    max_tokens=LLM_CONFIG["MAX_TOKENS"]
)

def convert_policy_rules_to_string(policy_rules: dict) -> str:
    """
    Converts policy rules to a string.
    
    Args:
        policy_rules: Dictionary of policy rules or list of rules.
        
    Returns:
        String representation of policy rules.
    """
    results_text = []
    
    # Add header
    results_text.append("Policy Rules Summary:")
    results_text.append("=" * 50)
    
    # Handle both dictionary with 'rules' key and direct list of rules
    rules_to_process = []
    
    if isinstance(policy_rules, list):
        # If policy_rules is already a list, use it directly
        rules_to_process = policy_rules
    elif isinstance(policy_rules, dict) and "rules" in policy_rules:
        # If policy_rules is a dict with 'rules' key, use that list
        rules_to_process = policy_rules["rules"]
    else:
        return "No valid policy rules provided"
    
    # Iterate over all rules
    for rule in rules_to_process:
        if rule["type"] == "info" and "message" in rule:
            # Add the rule message
            results_text.append(rule["message"])
            
            # Add role information
            if "role" in rule and rule["role"]:
                roles = [r.get("role", r.get("value", "Unknown")) for r in rule["role"]]
                results_text.append(f"Roles: {', '.join(roles)}")
            
            # Add resource information
            if "resource" in rule and rule["resource"]:
                resources = [r.get("value", "Unknown") for r in rule["resource"]]
                results_text.append(f"Resources: {', '.join(resources)}")
            
            # Add action information
            if "action" in rule and rule["action"]:
                actions = [a.get("value", "Unknown") for a in rule["action"]]
                results_text.append(f"Actions: {', '.join(actions)}")
            
            # Add separator between rules
            results_text.append("-" * 50)
    return "\n".join(results_text)




def parse_llm_json_response(response: str) -> Dict[str, Any]:
    """Parse JSON response from LLM, handling markdown code blocks.
    
    Args:
        response: Raw response string from LLM
        
    Returns:
        Parsed JSON data as a dictionary
        
    Raises:
        json.JSONDecodeError: If response cannot be parsed as JSON
    """
    # Clean up response if it contains markdown code block formatting
    response = response.strip()
    if response.startswith('```'):
        # Extract JSON from markdown code block
        # Remove opening markdown code block
        if '```json' in response:
            response = response.split('```json', 1)[1]
        elif '```' in response:
            response = response.split('```', 1)[1]
        # Remove closing markdown code block if present
        if '```' in response:
            response = response.split('```', 1)[0]
        response = response.strip()
    
    # Parse and return the JSON data
    return json.loads(response)

def validate_policy_with_llm(query: str, rules: str) -> dict:
    """Validate policy rules using Azure OpenAI LLM.
    
    Args:
        query: The user query for policy validation
        rules: The validation results from policy validation as string
        
    Returns:
        Dictionary with LLM analysis of the policy validation results and status:
        - "success": All rules are in match, none in deviation
        - "warning": Some rules in match, some in deviation
        - "error": No rules in match, all in deviation or no rules found
    """
    try:
        # Create system prompt for policy validation
        system_message = LLM_PROMPTS.get("POLICY_VALIDATION_SYSTEM_MESSAGE", "")
        
        # Create user prompt with validation results and query
        user_message = f"""
        Analyze the following policy rules based on this query: "{query}"
        
        Rules:
        {rules}
        
        Provide your analysis in the following JSON format:
        {{
           "query": "The user query for rules and authorization",
           "match": "List of rules that matches the query",
           "deviation": "List of rules that does not match the query"
        }}        
        """
        
        # Create the prompt template
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=system_message),
            HumanMessage(content=user_message)
        ])
        
        # Create the chain
        chain = prompt | policy_validation_llm | StrOutputParser()
        
        # Execute the chain
        response = chain.invoke({})
        
        # Parse the LLM response
        try:
            result = parse_llm_json_response(response)
            
            # Determine validation status based on match and deviation content
            match_content = result.get("match", "")
            deviation_content = result.get("deviation", "")
            
            # Check if match is empty or indicates no matches
            match_empty = not match_content
            
            # Check if deviation is empty or indicates no deviations
            deviation_empty = not deviation_content
            
            if match_empty:
                # No rules match the query - this is an error
                status = "error"
                message = "No rules match the user requirements. Policy changes are needed."
            elif not deviation_empty:
                # Some rules match but there are deviations - this is a warning
                status = "warning"
                message = "Some rules match the requirements, but there are deviations that should be addressed."
            else:
                # All rules match and no deviations - this is success
                status = "success"
                message = "All rules match the requirements. No policy changes needed."
                
            return {
                "status": status,
                "message": message,
                "analysis": result
            }
        except json.JSONDecodeError as e:
            # If parsing fails, return the raw response
            return {
                "status": "parsing_error",
                "message": f"Failed to parse LLM response as JSON: {str(e)}",
                "raw_response": response
            }
            
    except Exception as e:
        return {"status": "error", "message": f"Error validating policy with LLM: {str(e)}"} 


if __name__ == "__main__":
    # For testing purposes
    result = policy_validation_tool("Dette er min query babygurl","/Users/johanne.norland/Documents/intro-prosjekt/konkursbo-faktiskledelseogeier/App/config/authorization/policy.xml")
    print(result)